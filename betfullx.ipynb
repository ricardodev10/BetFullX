{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas necessárias\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, timedelta\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Para autenticação no Google Colab\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para execução local\n",
    "# Caminho para o arquivo JSON da chave de serviço\n",
    "key_path = \"./key/betfullx-soccer-447401-fd91f214194a.json\"\n",
    "\n",
    "# Autenticação\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 9\n"
     ]
    }
   ],
   "source": [
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Acessa as variáveis de ambiente\n",
    "API_KEY = os.getenv('API_KEY')\n",
    "API_URL = os.getenv('API_URL')\n",
    "PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "DATASET_NAME = os.getenv('DATASET_NAME')\n",
    "FULL_LOAD_DATE = os.getenv('FULL_LOAD_DATE')\n",
    "LEAGUE = int(os.getenv('LEAGUE'))\n",
    "SEASON = int(os.getenv('SEASON'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = [\n",
    "    {\n",
    "        \"table\": \"past_fixtures\",\n",
    "        \"write_disposition\": \"WRITE_APPEND\",\n",
    "        \"path\": \"fixtures\",\n",
    "        \"quality_control\": False,\n",
    "        \"params\": {\n",
    "            \"league\": LEAGUE,\n",
    "            \"season\": SEASON\n",
    "        },\n",
    "        \"incremental_load_params\": {\n",
    "            \"from\": \"YYYY-MM-DD\",\n",
    "            \"to\": \"YYYY-MM-DD\"\n",
    "        },\n",
    "        \"fields\": [],\n",
    "        \"nested_fields\": [\n",
    "            \"fixture.id\",\n",
    "            \"fixture.referee\",\n",
    "            \"fixture.timezone\",\n",
    "            \"fixture.date\",\n",
    "            \"fixture.timestamp\",\n",
    "            \"fixture.periods.first\",\n",
    "            \"fixture.periods.second\",\n",
    "            \"fixture.venue.id\",\n",
    "            \"fixture.venue.name\",\n",
    "            \"fixture.venue.city\",\n",
    "            \"fixture.status.long\",\n",
    "            \"fixture.status.short\",\n",
    "            \"fixture.status.elapsed\",\n",
    "            \"league.id\",\n",
    "            \"league.name\",\n",
    "            \"league.country\",\n",
    "            \"league.logo\",\n",
    "            \"league.flag\",\n",
    "            \"league.season\",\n",
    "            \"league.round\",\n",
    "            \"teams.home.id\",\n",
    "            \"teams.home.name\",\n",
    "            \"teams.home.logo\",\n",
    "            \"teams.home.winner\",\n",
    "            \"teams.away.id\",\n",
    "            \"teams.away.name\",\n",
    "            \"teams.away.logo\",\n",
    "            \"teams.away.winner\",\n",
    "            \"goals.home\",\n",
    "            \"goals.away\",\n",
    "            \"score.halftime.home\",\n",
    "            \"score.halftime.away\",\n",
    "            \"score.fulltime.home\",\n",
    "            \"score.fulltime.away\",\n",
    "            \"score.extratime.home\",\n",
    "            \"score.extratime.away\",\n",
    "            \"score.penalty.home\",\n",
    "            \"score.penalty.away\"\n",
    "        ],\n",
    "        \"repeatable_fields\": []\n",
    "    },\n",
    "    {\n",
    "        \"table\": \"future_fixtures\",\n",
    "        \"write_disposition\": \"WRITE_TRUNCATE\",\n",
    "        \"path\": \"fixtures\",\n",
    "        \"quality_control\": False,\n",
    "        \"params\": {\n",
    "            \"league\": LEAGUE,\n",
    "            \"season\": SEASON,\n",
    "            \"to\": \"2099-12-31\"\n",
    "        },\n",
    "        \"incremental_load_params\": {\n",
    "            \"from\": \"YYYY-MM-DD\",\n",
    "        },\n",
    "        \"fields\": [],\n",
    "        \"nested_fields\": [\n",
    "            \"fixture.id\",\n",
    "            \"fixture.timezone\",\n",
    "            \"fixture.date\",\n",
    "            \"fixture.timestamp\",\n",
    "            \"fixture.venue.id\",\n",
    "            \"fixture.venue.name\",\n",
    "            \"fixture.venue.city\",\n",
    "            \"fixture.status.long\",\n",
    "            \"fixture.status.short\",\n",
    "            \"league.id\",\n",
    "            \"league.name\",\n",
    "            \"league.country\",\n",
    "            \"league.logo\",\n",
    "            \"league.flag\",\n",
    "            \"league.season\",\n",
    "            \"league.round\",\n",
    "            \"teams.home.id\",\n",
    "            \"teams.home.name\",\n",
    "            \"teams.home.logo\",\n",
    "            \"teams.away.id\",\n",
    "            \"teams.away.name\",\n",
    "            \"teams.away.logo\"\n",
    "        ],\n",
    "        \"repeatable_fields\": []\n",
    "    },\n",
    "    {\n",
    "        \"table\": \"players\",\n",
    "        \"write_disposition\": \"WRITE_TRUNCATE\",\n",
    "        \"path\": \"players\",\n",
    "        \"quality_control\": True,\n",
    "        \"params\": {\n",
    "            \"league\": LEAGUE,\n",
    "            \"season\": SEASON,\n",
    "            \"page\": 1\n",
    "        },\n",
    "        \"fields\": [],\n",
    "        \"nested_fields\": [\n",
    "            \"player.id\",\n",
    "            \"player.name\",\n",
    "            \"player.firstname\",\n",
    "            \"player.lastname\",\n",
    "            \"player.age\",\n",
    "            \"player.birth.date\",\n",
    "            \"player.birth.place\",\n",
    "            \"player.nationality\",\n",
    "            \"player.height\",\n",
    "            \"player.weight\",\n",
    "            \"player.injured\",\n",
    "            \"player.photo\"\n",
    "        ],\n",
    "        \"repeatable_fields\": []\n",
    "    },\n",
    "]\n",
    "\n",
    "iterable_endpoints = {\n",
    "    \"past_fixtures\": [\n",
    "        {\n",
    "            \"table\": \"fixturesStatistics\",\n",
    "            \"write_disposition\": \"WRITE_APPEND\",\n",
    "            \"path\": \"fixtures/statistics\",\n",
    "            \"query_param\": {\n",
    "                \"fixture\": \"fixture.id\"\n",
    "            },\n",
    "            \"fixed_params\": {},\n",
    "            \"fields\": [\"fixture\"],\n",
    "            \"nested_fields\": [\n",
    "                \"team.id\",\n",
    "                \"team.name\",\n",
    "                \"team.logo\"\n",
    "            ],\n",
    "            \"repeatable_fields\": [\n",
    "                \"statistics\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"table\": \"fixturesLineups\",\n",
    "            \"write_disposition\": \"WRITE_APPEND\",\n",
    "            \"path\": \"fixtures/lineups\",\n",
    "            \"query_param\": {\n",
    "                \"fixture\": \"fixture.id\"\n",
    "            },\n",
    "            \"fixed_params\": {},\n",
    "            \"fields\": [\n",
    "                \"fixture\",\n",
    "                \"formation\"\n",
    "            ],\n",
    "            \"nested_fields\": [\n",
    "                \"team.id\"\n",
    "            ],\n",
    "            \"repeatable_fields\": [\n",
    "                \"startXI\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(path, params, headers):\n",
    "    all_data = []\n",
    "    while True:\n",
    "        response = requests.get(f\"{API_URL}/{path}\", headers=headers, params=params)\n",
    "        data = response.json()\n",
    "        print(response.text)\n",
    "        if 'response' in data and data['response']:\n",
    "            all_data.extend(data['response'])\n",
    "            if 'page' in params:\n",
    "                params['page'] += 1\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return all_data\n",
    "\n",
    "def fetch_iterable_data(main_data, iterable_endpoint):\n",
    "    all_data = []\n",
    "    for _, item in main_data.iterrows():\n",
    "        query_params = {key: item[value.replace('.', '__')] for key, value in iterable_endpoint[\"query_param\"].items()}\n",
    "        params = query_params.copy()\n",
    "        params.update(iterable_endpoint['fixed_params'])\n",
    "        data = fetch_data(iterable_endpoint['path'], params, HEADERS)\n",
    "\n",
    "        iterated_data = [{**query_params, **item} for item in data]\n",
    "        all_data.extend(iterated_data)\n",
    "    return all_data\n",
    "\n",
    "def prepare_dataframe(data, fields, nested_fields, repeatable_fields):\n",
    "    for item in data:\n",
    "        for field in repeatable_fields:\n",
    "            if field in item:\n",
    "                for sub_item in item[field]:\n",
    "                    for key in sub_item.keys():\n",
    "                        sub_item[key] = str(sub_item[key])\n",
    "\n",
    "    meta_fields = fields + repeatable_fields\n",
    "\n",
    "    df = pd.json_normalize(data, sep='__', meta=meta_fields)\n",
    "\n",
    "    all_fields = fields + nested_fields + repeatable_fields\n",
    "    column_names = [col.replace('.', '__') for col in all_fields]\n",
    "\n",
    "    existing_columns = [col for col in column_names if col in df.columns]\n",
    "\n",
    "    df = df[existing_columns]\n",
    "    return df\n",
    "\n",
    "def create_dataset_if_not_exists(client, dataset_name):\n",
    "    try:\n",
    "        client.get_dataset(dataset_name)\n",
    "    except NotFound:\n",
    "        print(f\"Dataset {dataset_name} not found. Creating...\")\n",
    "        client.create_dataset(dataset_name)\n",
    "\n",
    "def get_table_schema(client, dataset_name, table_name):\n",
    "    table_ref = client.dataset(dataset_name).table(table_name)\n",
    "    table = client.get_table(table_ref)\n",
    "    return table.schema\n",
    "\n",
    "def load_data_to_bigquery(client, dataset_name, table_name, data, write_disposition, partition_column=None, clustering_fields=None):\n",
    "    table_ref = client.dataset(dataset_name).table(table_name)\n",
    "\n",
    "    try:\n",
    "        table = client.get_table(table_ref)\n",
    "        schema = table.schema\n",
    "    except NotFound:\n",
    "        schema = None\n",
    "        print(f\"Schema para a tabela {DATASET_NAME}.{table_name} não encontrada.\")\n",
    "\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=write_disposition,\n",
    "    )\n",
    "    if schema:\n",
    "        job_config.schema = schema\n",
    "    else:\n",
    "        job_config.autodetect = True\n",
    "\n",
    "    json_str = data.to_json(orient='records', date_format='iso')\n",
    "    job = client.load_table_from_json(json.loads(json_str), table_ref, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"Foram carregadas {len(data)} linhas em {dataset_name}.{table_name}\")\n",
    "\n",
    "def get_last_update(client, now):\n",
    "    table_name = f'{PROJECT_ID}.{DATASET_NAME}.updates'\n",
    "    query = f'SELECT MAX(updated_at) AS last_update FROM `{table_name}`'\n",
    "\n",
    "    try:\n",
    "        client.get_table(table_name)\n",
    "    except NotFound:\n",
    "        print(f\"Table {table_name} not found. Initializing with FULL_LOAD_DATE: {FULL_LOAD_DATE}\")\n",
    "        full_load_date = datetime.strptime(FULL_LOAD_DATE, '%Y-%m-%d')\n",
    "        initial_data = [{'updated_at': full_load_date}]\n",
    "        load_data_to_bigquery(client, DATASET_NAME, 'updates', pd.DataFrame(initial_data), 'WRITE_TRUNCATE')\n",
    "        return full_load_date\n",
    "\n",
    "    try:\n",
    "        query_job = client.query(query)\n",
    "        results = query_job.result()\n",
    "\n",
    "        for row in results:\n",
    "            print(f\"Ultima data de atualização: {row.last_update}\")\n",
    "            return row.last_update if row.last_update else now - timedelta(days=1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while executing the query: {e}\")\n",
    "        return None\n",
    "\n",
    "def log_update(client,now):\n",
    "    table_name = f'{PROJECT_ID}.{DATASET_NAME}.updates'\n",
    "    updated_at = [{'updated_at': now}]\n",
    "    load_data_to_bigquery(client, DATASET_NAME, 'updates', pd.DataFrame(updated_at), 'WRITE_APPEND')\n",
    "\n",
    "def incremental_params_update(table, incremental_load_params, params, last_update, now):\n",
    "    if table == \"past_fixtures\":\n",
    "        params.update({\n",
    "            #'from': last_update.strftime('%Y-%m-%d'), #Aqui pega do último update pra frente\n",
    "            'from': '2023-01-01',  # Data inicial fixa\n",
    "            'to': (now - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "        })\n",
    "    elif table == \"future_fixtures\":\n",
    "        params.update({\n",
    "            'from': now.strftime('%Y-%m-%d')\n",
    "        })\n",
    "    else:\n",
    "        params\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(request=None):\n",
    "    client = bigquery.Client(project=PROJECT_ID)\n",
    "    create_dataset_if_not_exists(client, DATASET_NAME)\n",
    "    now = datetime.now()\n",
    "    # now = datetime(2024, 6, 1, 0, 0)\n",
    "    last_update = get_last_update(client, now)\n",
    "    main_endpoints = endpoints.copy()\n",
    "    main_iterable_endpoints = iterable_endpoints.copy()\n",
    "\n",
    "    for endpoint in main_endpoints:\n",
    "        params = endpoint.get('params', {})\n",
    "        table = endpoint.get('table')\n",
    "        incremental_load_params = endpoint.get('incremental_load_params')\n",
    "        path = endpoint.get('path')\n",
    "        fields = endpoint.get('fields')\n",
    "        nested_fields = endpoint.get('nested_fields')\n",
    "        repeatable_fields = endpoint.get('repeatable_fields')\n",
    "        write_disposition = endpoint.get('write_disposition')\n",
    "        quality_control = endpoint.get('quality_control', False)\n",
    "\n",
    "        if incremental_load_params:\n",
    "            params = incremental_params_update(table, incremental_load_params, params, last_update, now)\n",
    "\n",
    "        raw_data = fetch_data(path, params, HEADERS)\n",
    "\n",
    "        if raw_data:\n",
    "            prepared_data = prepare_dataframe(raw_data, fields, nested_fields, repeatable_fields)\n",
    "            load_data_to_bigquery(client, DATASET_NAME, table, prepared_data, write_disposition)\n",
    "\n",
    "            if table in main_iterable_endpoints:\n",
    "                for iterable_endpoint in main_iterable_endpoints[table]:\n",
    "                    iterable_table = iterable_endpoint.get('table')\n",
    "                    iterable_fields = iterable_endpoint.get('fields')\n",
    "                    iterable_nested_fields = iterable_endpoint.get('nested_fields')\n",
    "                    iterable_repeatable_fields = iterable_endpoint.get('repeatable_fields')\n",
    "                    iterable_write_disposition = iterable_endpoint.get('write_disposition')\n",
    "\n",
    "                    print(f\"Buscando os dados iteráveis para o endpoint: {iterable_table}\")\n",
    "                    detailed_data = fetch_iterable_data(prepared_data, iterable_endpoint)\n",
    "\n",
    "                    if detailed_data:\n",
    "                        prepared_iterable_data = prepare_dataframe(detailed_data, iterable_fields, iterable_nested_fields, iterable_repeatable_fields)\n",
    "                        load_data_to_bigquery(client, DATASET_NAME, iterable_table, prepared_iterable_data, iterable_write_disposition)\n",
    "                    else:\n",
    "                        print(f\"Não foram encontrados dados para o endpoint: {iterable_table}\")\n",
    "        else:\n",
    "            print(f\"Não foram encontrados dados para o endpoint: {table}\")\n",
    "\n",
    "    log_update(client, now)\n",
    "\n",
    "    return \"success\", 200\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
